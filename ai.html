<!DOCTYPE html>
<html lang="en">
<head>
<!-- 2021-12-07 Tue 22:45 -->
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1">
<title>Machine Learning From Scratch</title>
<meta name="generator" content="Org mode">
<meta name="author" content="jbh">
<style type="text/css">
 <!--/*--><![CDATA[/*><!--*/
  .title  { text-align: center;
             margin-bottom: .2em; }
  .subtitle { text-align: center;
              font-size: medium;
              font-weight: bold;
              margin-top:0; }
  .todo   { font-family: monospace; color: red; }
  .done   { font-family: monospace; color: green; }
  .priority { font-family: monospace; color: orange; }
  .tag    { background-color: #eee; font-family: monospace;
            padding: 2px; font-size: 80%; font-weight: normal; }
  .timestamp { color: #bebebe; }
  .timestamp-kwd { color: #5f9ea0; }
  .org-right  { margin-left: auto; margin-right: 0px;  text-align: right; }
  .org-left   { margin-left: 0px;  margin-right: auto; text-align: left; }
  .org-center { margin-left: auto; margin-right: auto; text-align: center; }
  .underline { text-decoration: underline; }
  #postamble p, #preamble p { font-size: 90%; margin: .2em; }
  p.verse { margin-left: 3%; }
  body {
  max-width: 40rem;
  padding: 1rem;
  margin: auto;
  }
  pre {
    border: 1px solid #ccc;
    box-shadow: 3px 3px 3px #eee;
    padding: 8pt;
    font-family: monospace;
    overflow: auto;
    margin: 1.2em;
  }
  pre.src {
    position: relative;
    overflow: auto;
    padding-top: 1.2em;
  }
  pre.src:before {
    display: none;
    position: absolute;
    background-color: white;
    top: -10px;
    right: 10px;
    padding: 3px;
    border: 1px solid black;
  }
  pre.src:hover:before { display: inline; margin-top: 14px;}
  /* Languages per Org manual */
  pre.src-asymptote:before { content: 'Asymptote'; }
  pre.src-awk:before { content: 'Awk'; }
  pre.src-C:before { content: 'C'; }
  /* pre.src-C++ doesn't work in CSS */
  pre.src-clojure:before { content: 'Clojure'; }
  pre.src-css:before { content: 'CSS'; }
  pre.src-D:before { content: 'D'; }
  pre.src-ditaa:before { content: 'ditaa'; }
  pre.src-dot:before { content: 'Graphviz'; }
  pre.src-calc:before { content: 'Emacs Calc'; }
  pre.src-emacs-lisp:before { content: 'Emacs Lisp'; }
  pre.src-fortran:before { content: 'Fortran'; }
  pre.src-gnuplot:before { content: 'gnuplot'; }
  pre.src-haskell:before { content: 'Haskell'; }
  pre.src-hledger:before { content: 'hledger'; }
  pre.src-java:before { content: 'Java'; }
  pre.src-js:before { content: 'Javascript'; }
  pre.src-latex:before { content: 'LaTeX'; }
  pre.src-ledger:before { content: 'Ledger'; }
  pre.src-lisp:before { content: 'Lisp'; }
  pre.src-lilypond:before { content: 'Lilypond'; }
  pre.src-lua:before { content: 'Lua'; }
  pre.src-matlab:before { content: 'MATLAB'; }
  pre.src-mscgen:before { content: 'Mscgen'; }
  pre.src-ocaml:before { content: 'Objective Caml'; }
  pre.src-octave:before { content: 'Octave'; }
  pre.src-org:before { content: 'Org mode'; }
  pre.src-oz:before { content: 'OZ'; }
  pre.src-plantuml:before { content: 'Plantuml'; }
  pre.src-processing:before { content: 'Processing.js'; }
  pre.src-python:before { content: 'Python'; }
  pre.src-R:before { content: 'R'; }
  pre.src-ruby:before { content: 'Ruby'; }
  pre.src-sass:before { content: 'Sass'; }
  pre.src-scheme:before { content: 'Scheme'; }
  pre.src-screen:before { content: 'Gnu Screen'; }
  pre.src-sed:before { content: 'Sed'; }
  pre.src-sh:before { content: 'shell'; }
  pre.src-sql:before { content: 'SQL'; }
  pre.src-sqlite:before { content: 'SQLite'; }
  /* additional languages in org.el's org-babel-load-languages alist */
  pre.src-forth:before { content: 'Forth'; }
  pre.src-io:before { content: 'IO'; }
  pre.src-J:before { content: 'J'; }
  pre.src-makefile:before { content: 'Makefile'; }
  pre.src-maxima:before { content: 'Maxima'; }
  pre.src-perl:before { content: 'Perl'; }
  pre.src-picolisp:before { content: 'Pico Lisp'; }
  pre.src-scala:before { content: 'Scala'; }
  pre.src-shell:before { content: 'Shell Script'; }
  pre.src-ebnf2ps:before { content: 'ebfn2ps'; }
  /* additional language identifiers per "defun org-babel-execute"
       in ob-*.el */
  pre.src-cpp:before  { content: 'C++'; }
  pre.src-abc:before  { content: 'ABC'; }
  pre.src-coq:before  { content: 'Coq'; }
  pre.src-groovy:before  { content: 'Groovy'; }
  /* additional language identifiers from org-babel-shell-names in
     ob-shell.el: ob-shell is the only babel language using a lambda to put
     the execution function name together. */
  pre.src-bash:before  { content: 'bash'; }
  pre.src-csh:before  { content: 'csh'; }
  pre.src-ash:before  { content: 'ash'; }
  pre.src-dash:before  { content: 'dash'; }
  pre.src-ksh:before  { content: 'ksh'; }
  pre.src-mksh:before  { content: 'mksh'; }
  pre.src-posh:before  { content: 'posh'; }
  /* Additional Emacs modes also supported by the LaTeX listings package */
  pre.src-ada:before { content: 'Ada'; }
  pre.src-asm:before { content: 'Assembler'; }
  pre.src-caml:before { content: 'Caml'; }
  pre.src-delphi:before { content: 'Delphi'; }
  pre.src-html:before { content: 'HTML'; }
  pre.src-idl:before { content: 'IDL'; }
  pre.src-mercury:before { content: 'Mercury'; }
  pre.src-metapost:before { content: 'MetaPost'; }
  pre.src-modula-2:before { content: 'Modula-2'; }
  pre.src-pascal:before { content: 'Pascal'; }
  pre.src-ps:before { content: 'PostScript'; }
  pre.src-prolog:before { content: 'Prolog'; }
  pre.src-simula:before { content: 'Simula'; }
  pre.src-tcl:before { content: 'tcl'; }
  pre.src-tex:before { content: 'TeX'; }
  pre.src-plain-tex:before { content: 'Plain TeX'; }
  pre.src-verilog:before { content: 'Verilog'; }
  pre.src-vhdl:before { content: 'VHDL'; }
  pre.src-xml:before { content: 'XML'; }
  pre.src-nxml:before { content: 'XML'; }
  /* add a generic configuration mode; LaTeX export needs an additional
     (add-to-list 'org-latex-listings-langs '(conf " ")) in .emacs */
  pre.src-conf:before { content: 'Configuration File'; }

  table { border-collapse:collapse; }
  caption.t-above { caption-side: top; }
  caption.t-bottom { caption-side: bottom; }
  td, th { vertical-align:top;  }
  th.org-right  { text-align: center;  }
  th.org-left   { text-align: center;   }
  th.org-center { text-align: center; }
  td.org-right  { text-align: right;  }
  td.org-left   { text-align: left;   }
  td.org-center { text-align: center; }
  dt { font-weight: bold; }
  .footpara { display: inline; }
  .footdef  { margin-bottom: 1em; }
  .figure { padding: 1em; }
  .figure p { text-align: center; }
  .equation-container {
    display: table;
    text-align: center;
    width: 100%;
  }
  .equation {
    vertical-align: middle;
  }
  .equation-label {
    display: table-cell;
    text-align: right;
    vertical-align: middle;
  }
  .inlinetask {
    padding: 10px;
    border: 2px solid gray;
    margin: 10px;
    background: #ffffcc;
  }
  #org-div-home-and-up
   { text-align: right; font-size: 70%; white-space: nowrap; }
  textarea { overflow-x: auto; }
  .linenr { font-size: smaller }
  .code-highlighted { background-color: #ffff00; }
  .org-info-js_info-navigation { border-style: none; }
  #org-info-js_console-label
    { font-size: 10px; font-weight: bold; white-space: nowrap; }
  .org-info-js_search-highlight
    { background-color: #ffff00; color: #000000; font-weight: bold; }
  .org-svg { width: 90%; }
  /*]]>*/-->
</style>
<style> body {background-color: #fafad2} </style>
<script type="text/javascript">
// @license magnet:?xt=urn:btih:e95b018ef3580986a04669f1b5879592219e2a7a&dn=public-domain.txt Public Domain
<!--/*--><![CDATA[/*><!--*/
     function CodeHighlightOn(elem, id)
     {
       var target = document.getElementById(id);
       if(null != target) {
         elem.classList.add("code-highlighted");
         target.classList.add("code-highlighted");
       }
     }
     function CodeHighlightOff(elem, id)
     {
       var target = document.getElementById(id);
       if(null != target) {
         elem.classList.remove("code-highlighted");
         target.classList.remove("code-highlighted");
       }
     }
    /*]]>*///-->
// @license-end
</script>
</head>
<body>
<div id="content">
<header>
<h1 class="title">Machine Learning From Scratch</h1>
</header><nav id="table-of-contents">
<h2>Table of Contents</h2>
<div id="text-table-of-contents">
<ul>
<li><a href="#Intro">Intro</a>
<ul>
<li><a href="#Applied">Applied</a></li>
<li><a href="#Choose%20your%20own%20theory%2Falgorithm%20course">Choose your own theory/algorithm course</a></li>
<li><a href="#Theoretic%20Foundations%20of%20Modern%20Machine%20Learning">Theoretic Foundations of Modern Machine Learning</a></li>
</ul>
</li>
<li><a href="#Begin">Begin</a>
<ul>
<li><a href="#Get%20a%20math%20crash%20course%20reference">Get a math crash course reference</a></li>
<li><a href="#Install%20Software">Install Software</a></li>
<li><a href="#Applied%20ML%20lecture%201">Applied ML lecture 1</a></li>
</ul>
</li>
</ul>
</div>
</nav>

<div id="outline-container-Intro" class="outline-2">
<h2 id="Intro">Intro</h2>
<div class="outline-text-2" id="text-Intro">
<p>
This is the 2.0 version of this workshop after I audited many AI courses and filtered for the best resources. All the prereqs of probability, linear algebra/vector calculus will be covered as we go. Any books can be found on <a href="http://libgen.is/">library genesis</a>.
</p>
</div>

<div id="outline-container-Applied" class="outline-3">
<h3 id="Applied">Applied</h3>
<div class="outline-text-3" id="text-Applied">
<p>
We will do a short-ish course taught by a core-developer of the scikit-learn library, he will also teach us how to <a href="https://www.youtube.com/playlist?list=PLM-1QqX7UksT6tREbR-n9Mhup0OoRBU34">contribute</a>. The slides are annotated with commentary if you press P while viewing (or click the speech bubble icon). This will also cover Keras, AutoML libraries. 
</p>

<ul class="org-ul">
<li>COMS-W4995 <a href="https://www.cs.columbia.edu/~amueller/comsw4995s20/schedule/">Applied Machine Learning</a> Columbia
<ul class="org-ul">
<li><b>Course assumes you are taking a theory course in parallel</b></li>
<li>Can be done entirely in google colab (free) on a tablet/phone if you have to</li>
<li>21 lectures on <a href="https://www.youtube.com/playlist?list=PL_pVmAaAnxIRnSw6wiCpSvshFyCREZmlM">YouTube</a></li>
<li>Homework on <a href="https://github.com/amueller/COMS4995-s20/tree/master/homework">GitHub</a></li>
<li>Books recommended:
<ul class="org-ul">
<li><a href="http://appliedpredictivemodeling.com/">Applied Predictive Modeling</a></li>
<li><a href="https://amueller.github.io/#book">Intro to Machine Learning w/Python</a></li>
<li><a href="https://clauswilke.com/dataviz/">Fundamentals of Data Visualization</a></li>
</ul></li>
</ul></li>
</ul>
</div>
</div>

<div id="outline-container-Choose%20your%20own%20theory%2Falgorithm%20course" class="outline-3">
<h3 id="Choose%20your%20own%20theory%2Falgorithm%20course">Choose your own theory/algorithm course</h3>
<div class="outline-text-3" id="text-Choose%20your%20own%20theory%2Falgorithm%20course">
<p>
I audited most of these courses, mix and match your own curriculum to go with COMS-W4995. If one topic doesn't make sense like AdaBoost or Perceptron in one course, try watching it in another.    
</p>

<p>
<b>CS4780</b>   
This is the best of all the intro theory/algorithm style ML courses as the prof will actually explain the math notation and motivation behind the theory. A small picture on a board in chaulk of a hyperplane vector will be much easier to understand than an entire hour of somebody talking about it in a zoom lecture with static slides filled with notation. It doesn't matter if the lectures are from 2018 because it's almost the <a href="https://www.cs.cornell.edu/courses/cs4780/2021fa/#Schedule">same</a> as the 2021 version, and all these topics come back into fashion again such as the recent <a href="https://www.youtube.com/watch?v=ahRPdiCop3E">paper</a> <i>Every Model Learned by Gradient Descent Is Approximately a Kernel Machine</i>.   
</p>

<ul class="org-ul">
<li>CS4780 <a href="https://www.cs.cornell.edu/courses/cs4780/2018fa/">Machine Learning for Intelligent Systems</a> Cornell 
<ul class="org-ul">
<li>37 lectures on <a href="https://www.youtube.com/playlist?list=PLl8OlHZGYOQ7bkVbuRthEsaLr7bONzbXS">YouTube</a> w/<a href="http://www.cs.cornell.edu/courses/cs4780/2018fa/lectures/index.html">notes</a></li>
<li>Homework w/solutions on <a href="https://www.dropbox.com/s/tbxnjzk5w67u0sp/Homeworks.zip?dl=0">dropbox</a></li>
<li>Books recommended:
<ul class="org-ul">
<li><a href="https://probml.github.io/pml-book/book1.html">Probabilistic Machine Learning</a> (2021 draft) includes Jupyter <a href="https://github.com/probml/pyprobml/tree/master/book1">notebooks</a> for each chapter</li>
<li><a href="https://web.stanford.edu/~hastie/ElemStatLearn/">The Elements of Statistical Learning</a></li>
</ul></li>
</ul></li>
</ul>

<p>
<b>CS480</b>
This course focuses on neural network models as they are the most hyped right now though see the above paper on neural network kernel machine approximation, some of the NN models have mind boggling amounts of parameters requiring large scale distributed machine learning. CS4780 will also cover much of the material here like AdaBoost, Perceptron, SVM etc so if they don't make sense, watch them again in CS4780.     
</p>

<ul class="org-ul">
<li>CS480 <a href="https://cs.uwaterloo.ca/~y328yu/mycourses/480/lecture.html">Introduction to Machine Learning</a> Waterloo
<ul class="org-ul">
<li>All the lectures .mp4 on the same site (noticed Privacy lecture missing)</li>
<li>Homework is open using public datasets to use with Pytorch</li>
<li>Covers causality models, adversarial models, the most recent neural network models</li>
<li>Books recommended:
<ul class="org-ul">
<li><a href="https://en.d2l.ai/">Dive into Deep Learning</a></li>
<li><a href="https://mml-book.github.io/">Mathematics for Machine Learning</a></li>
</ul></li>
</ul></li>
</ul>

<p>
<b>10-701</b>
General graduate intro for students who aren't specializing in machine learning and want to use it for other fields like systems biology. Taught by a <a href="http://www.cs.cmu.edu/~zivbj/">researcher</a> in <a href="https://algorithmsinnature.org/">algorithms used by nature</a> and Prof Xing the now president of <a href="https://mbzuai.ac.ae/">MBZUAI</a> (yes, you can get into MBZUAI). The lectures are worth watching as they will talk about what works now and what doesn't anymore, why there is a ton of classifiers, however it's a grad course so math sophistication is assumed. Very good lectures on computational learning theory and probabilistic graph models. 
</p>

<ul class="org-ul">
<li>10-701 <a href="https://www.cs.cmu.edu/~epxing/Class/10701-20/schedule.html">Intro to Machine Learning</a> CMU 
<ul class="org-ul">
<li>Lectures on <a href="https://www.youtube.com/playlist?list=PLsWN0V-b507g7dbQTUvFkKZEqdHR5Fh4P">YouTube</a></li>
<li>Homework is <a href="https://www.cs.cmu.edu/~epxing/Class/10701-20/">avail</a> also <a href="https://github.com/jiaqigeng/CMU-10701-Machine-Learning">2021 hw solutions</a></li>
</ul></li>
</ul>

<p>
<b>10-301</b>
Undergrad/MSc version of 10-701, errors in the slides and you have to watch the lectures as he handwrites all the algorithms on a tablet. If you don't understand a topic watch it again here for more clarity like the PAC learning theory lectures. 
</p>

<ul class="org-ul">
<li>10-301 <a href="http://www.cs.cmu.edu/~mgormley/courses/10601/schedule.html">Intro to Machine Learning</a> CMU
<ul class="org-ul">
<li>Lectures on <a href="https://www.youtube.com/playlist?list=PLpqQKYIU-snAPM89YPPwyQ9xdaiAdoouk">YouTube</a></li>
<li>Hw is all open, uses same books as CS4780</li>
<li>Can also be done entirely in google colab</li>
<li>Recitations w/<a href="http://www.cs.cmu.edu/~mgormley/courses/10601/schedule.html">solutions</a> on the 2021 schedule</li>
</ul></li>
</ul>


<p>
<b>CS-433</b>
Being taught right now (Dec 2021) is EPFL's machine learning course. Has more learning theory than most other intro courses which is good, I didn't try any assignments but the labs come with full solutions. 
</p>

<ul class="org-ul">
<li>CS-433 <a href="https://www.epfl.ch/labs/mlo/machine-learning-cs-433/">Machine Learning</a> EPFL
<ul class="org-ul">
<li>Lectures on <a href="https://www.youtube.com/playlist?list=PL4O4bXkI-fAd4nB7YYR5F8WitmPxjPeAa">YouTube</a></li>
<li>A lot of labs on <a href="https://github.com/epfml/ML_course/tree/master/labs">GitHub</a> w/solutions</li>
<li>Projects are <a href="https://www.aicrowd.com/challenges/epfl-machine-learning-higgs">competitions</a> I don't think you can audit without school login (I didn't try)</li>
</ul></li>
</ul>

<p>
<b>18.337J</b>
Try a research exploration into the crazy world of <a href="https://www.stochasticlifestyle.com/the-essential-tools-of-scientific-machine-learning-scientific-ml/">scientific ML</a> such as physics-informed neural networks where you can drop in partial differential equations which are the math models describing the rules of any system with spatial as well as time dependence such as diffusion (heat transfer, population dynamics), finance, biology systems, sound waves, fluid dynamics, electrodynamics, conservation laws, relativity and who knows how many more. These PDEs act as prior information which encode the physical laws of that system then 'data efficient' noisy samples can be learned from instead of requiring millions+ of carefully prepared samples like in typical supervised learning.
</p>

<p>
This course also covers large scale ML high performance computing   
</p>

<ul class="org-ul">
<li>18.337J <a href="https://github.com/mitmath/18337">Scientific Machine Learning</a> MIT
<ul class="org-ul">
<li>Lectures on <a href="https://www.youtube.com/playlist?list=PLCAl7tjCwWyGjdzOOnlbGnVNZk0kB8VSa">YouTube</a></li>
<li>Homework available on GitHub</li>
</ul></li>
</ul>

<p>
<b>Many More</b>
MIT now offers it's 2020 Machine Learning <a href="https://ocw.mit.edu/courses/electrical-engineering-and-computer-science/6-036-introduction-to-machine-learning-fall-2020/">course</a> on open library with class recorded blackboard lectures, even the classic Andrew NG machine learning course on Coursera is still worth doing.
</p>
</div>
</div>

<div id="outline-container-Theoretic%20Foundations%20of%20Modern%20Machine%20Learning" class="outline-3">
<h3 id="Theoretic%20Foundations%20of%20Modern%20Machine%20Learning">Theoretic Foundations of Modern Machine Learning</h3>
<div class="outline-text-3" id="text-Theoretic%20Foundations%20of%20Modern%20Machine%20Learning">
<p>
My choice of curriculum is to understand the core theory, so here I will go through the first 20 chapters of the (free) <a href="https://www.cs.huji.ac.il/~shais/UnderstandingMachineLearning/">book</a> <i>Understanding Machine Learning: From Theory to Algorithms</i> w/<a href="https://www.youtube.com/playlist?list=PLPW2keNyw-usgvmR7FTQ3ZRjfLs5jT4BO">lectures</a>. It's still taught by the author at <a href="https://student.cs.uwaterloo.ca/~cs485/">Waterloo</a> in 2021 and CMU's PhD track intro course <a href="http://www.cs.cmu.edu/~nihars/teaching/10715-Fa21/index.html">10-715</a>, and 10-701 covers some of it's chapters like Rademacher complexities. There's a <a href="https://www.cs.huji.ac.il/~shais/UnderstandingMachineLearning/MLbookSol.pdf">solutions manual</a> for the few exercises in the book which will be an exercise in itself to try and understand.
</p>

<p>
Every chapter in the book has a corresponding lecture in the above courses so I'll probably end up doing all of CS4780 and some of 10-701.
</p>
</div>
</div>
</div>

<div id="outline-container-Begin" class="outline-2">
<h2 id="Begin">Begin</h2>
<div class="outline-text-2" id="text-Begin">
</div>
<div id="outline-container-Get%20a%20math%20crash%20course%20reference" class="outline-3">
<h3 id="Get%20a%20math%20crash%20course%20reference">Get a math crash course reference</h3>
<div class="outline-text-3" id="text-Get%20a%20math%20crash%20course%20reference">
<p>
Obtain the <a href="http://libgen.is/book/index.php?md5=B228D58AB79295A264DBE0BFE4C9D06E">book</a> <i>All the Math You Missed But Need to Know for Graduate School</i> and the <a href="https://mml-book.github.io/">book</a> <i>Mathematics for Machine Learning</i> to use as a reference though we will still build up prereqs from scratch as we go.
</p>
</div>
</div>

<div id="outline-container-Install%20Software" class="outline-3">
<h3 id="Install%20Software">Install Software</h3>
<div class="outline-text-3" id="text-Install%20Software">
<p>
For COMS-4995 either install conda <a href="https://conda.io/projects/conda/en/latest/user-guide/tasks/manage-environments.html">locally</a> or use google colab (free). See <a href="https://docs.google.com/document/d/1RSGvlBG8dDfs62_0jJEHnQFN-Au6yFbp8M6QTNs3EIY/edit">this</a> brief tutorial for setting up google drive or how to <a href="https://www.kaggle.com/general/156610">directly</a> import kaggle datasets to colab. You can do all the intro ML courses entirely on a phone or tablet using colab if you had to.
</p>
</div>
</div>

<div id="outline-container-Applied%20ML%20lecture%201" class="outline-3">
<h3 id="Applied%20ML%20lecture%201">Applied ML lecture 1</h3>
<div class="outline-text-3" id="text-Applied%20ML%20lecture%201">
<p>
The coreqs for this course is the <a href="https://github.com/jakevdp/PythonDataScienceHandbook">Python Data Science Handbook</a> which you can quickly audit going through the <a href="https://github.com/jakevdp/PythonDataScienceHandbook/tree/master/notebooks">notebooks</a> on GitHub or just read the NumPy and Pandas <a href="https://numpy.org/doc/stable/user/basics.html">documentation</a> as those libraries comes up, if you did the <a href="./software.html">software</a> workshop this will be trivial. 
</p>

<p>
<a href="https://youtu.be/rbvpiPJuK64">Watch</a> or <a href="https://amueller.github.io/COMS4995-s20/slides/aml-01-introduction/#p1">read</a> the slides with notes though what he says in lecture is often different as the notes are from a previous semester and act as an outline. @50m he notes how ML is different that statistics as they're drawing up a hypothesis to ask a question about the data whereas we are making predictions on unseen data with models filled with assumptions. This course doesn't cover <a href="https://www.cs.cornell.edu/courses/cs4787/2021sp/">large scale machine learning</a> tooling as the prof will use AWS as his personal computer loading up an instance with 512GB ram to work on a large data subset instead of messing around with the massive complexity of distributed ML frameworks.
</p>

<p>
Reading: IMLP Ch 1, APM Ch 1-2
</p>

<p>
TODO
</p>
</div>
</div>
</div>
</div>
</body>
</html>
