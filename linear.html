<!DOCTYPE html>
<html lang="en">
<head>
<!-- 2021-08-05 Thu 21:53 -->
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1">
<title>Modern Applied Linear Algebra</title>
<meta name="generator" content="Org mode">
<meta name="author" content="jbh">
<style type="text/css">
 <!--/*--><![CDATA[/*><!--*/
  .title  { text-align: center;
             margin-bottom: .2em; }
  .subtitle { text-align: center;
              font-size: medium;
              font-weight: bold;
              margin-top:0; }
  .todo   { font-family: monospace; color: red; }
  .done   { font-family: monospace; color: green; }
  .priority { font-family: monospace; color: orange; }
  .tag    { background-color: #eee; font-family: monospace;
            padding: 2px; font-size: 80%; font-weight: normal; }
  .timestamp { color: #bebebe; }
  .timestamp-kwd { color: #5f9ea0; }
  .org-right  { margin-left: auto; margin-right: 0px;  text-align: right; }
  .org-left   { margin-left: 0px;  margin-right: auto; text-align: left; }
  .org-center { margin-left: auto; margin-right: auto; text-align: center; }
  .underline { text-decoration: underline; }
  #postamble p, #preamble p { font-size: 90%; margin: .2em; }
  p.verse { margin-left: 3%; }
  body {
  max-width: 40rem;
  padding: 1rem;
  margin: auto;
  }
  pre {
    border: 1px solid #ccc;
    box-shadow: 3px 3px 3px #eee;
    padding: 8pt;
    font-family: monospace;
    overflow: auto;
    margin: 1.2em;
  }
  pre.src {
    position: relative;
    overflow: auto;
    padding-top: 1.2em;
  }
  pre.src:before {
    display: none;
    position: absolute;
    background-color: white;
    top: -10px;
    right: 10px;
    padding: 3px;
    border: 1px solid black;
  }
  pre.src:hover:before { display: inline; margin-top: 14px;}
  /* Languages per Org manual */
  pre.src-asymptote:before { content: 'Asymptote'; }
  pre.src-awk:before { content: 'Awk'; }
  pre.src-C:before { content: 'C'; }
  /* pre.src-C++ doesn't work in CSS */
  pre.src-clojure:before { content: 'Clojure'; }
  pre.src-css:before { content: 'CSS'; }
  pre.src-D:before { content: 'D'; }
  pre.src-ditaa:before { content: 'ditaa'; }
  pre.src-dot:before { content: 'Graphviz'; }
  pre.src-calc:before { content: 'Emacs Calc'; }
  pre.src-emacs-lisp:before { content: 'Emacs Lisp'; }
  pre.src-fortran:before { content: 'Fortran'; }
  pre.src-gnuplot:before { content: 'gnuplot'; }
  pre.src-haskell:before { content: 'Haskell'; }
  pre.src-hledger:before { content: 'hledger'; }
  pre.src-java:before { content: 'Java'; }
  pre.src-js:before { content: 'Javascript'; }
  pre.src-latex:before { content: 'LaTeX'; }
  pre.src-ledger:before { content: 'Ledger'; }
  pre.src-lisp:before { content: 'Lisp'; }
  pre.src-lilypond:before { content: 'Lilypond'; }
  pre.src-lua:before { content: 'Lua'; }
  pre.src-matlab:before { content: 'MATLAB'; }
  pre.src-mscgen:before { content: 'Mscgen'; }
  pre.src-ocaml:before { content: 'Objective Caml'; }
  pre.src-octave:before { content: 'Octave'; }
  pre.src-org:before { content: 'Org mode'; }
  pre.src-oz:before { content: 'OZ'; }
  pre.src-plantuml:before { content: 'Plantuml'; }
  pre.src-processing:before { content: 'Processing.js'; }
  pre.src-python:before { content: 'Python'; }
  pre.src-R:before { content: 'R'; }
  pre.src-ruby:before { content: 'Ruby'; }
  pre.src-sass:before { content: 'Sass'; }
  pre.src-scheme:before { content: 'Scheme'; }
  pre.src-screen:before { content: 'Gnu Screen'; }
  pre.src-sed:before { content: 'Sed'; }
  pre.src-sh:before { content: 'shell'; }
  pre.src-sql:before { content: 'SQL'; }
  pre.src-sqlite:before { content: 'SQLite'; }
  /* additional languages in org.el's org-babel-load-languages alist */
  pre.src-forth:before { content: 'Forth'; }
  pre.src-io:before { content: 'IO'; }
  pre.src-J:before { content: 'J'; }
  pre.src-makefile:before { content: 'Makefile'; }
  pre.src-maxima:before { content: 'Maxima'; }
  pre.src-perl:before { content: 'Perl'; }
  pre.src-picolisp:before { content: 'Pico Lisp'; }
  pre.src-scala:before { content: 'Scala'; }
  pre.src-shell:before { content: 'Shell Script'; }
  pre.src-ebnf2ps:before { content: 'ebfn2ps'; }
  /* additional language identifiers per "defun org-babel-execute"
       in ob-*.el */
  pre.src-cpp:before  { content: 'C++'; }
  pre.src-abc:before  { content: 'ABC'; }
  pre.src-coq:before  { content: 'Coq'; }
  pre.src-groovy:before  { content: 'Groovy'; }
  /* additional language identifiers from org-babel-shell-names in
     ob-shell.el: ob-shell is the only babel language using a lambda to put
     the execution function name together. */
  pre.src-bash:before  { content: 'bash'; }
  pre.src-csh:before  { content: 'csh'; }
  pre.src-ash:before  { content: 'ash'; }
  pre.src-dash:before  { content: 'dash'; }
  pre.src-ksh:before  { content: 'ksh'; }
  pre.src-mksh:before  { content: 'mksh'; }
  pre.src-posh:before  { content: 'posh'; }
  /* Additional Emacs modes also supported by the LaTeX listings package */
  pre.src-ada:before { content: 'Ada'; }
  pre.src-asm:before { content: 'Assembler'; }
  pre.src-caml:before { content: 'Caml'; }
  pre.src-delphi:before { content: 'Delphi'; }
  pre.src-html:before { content: 'HTML'; }
  pre.src-idl:before { content: 'IDL'; }
  pre.src-mercury:before { content: 'Mercury'; }
  pre.src-metapost:before { content: 'MetaPost'; }
  pre.src-modula-2:before { content: 'Modula-2'; }
  pre.src-pascal:before { content: 'Pascal'; }
  pre.src-ps:before { content: 'PostScript'; }
  pre.src-prolog:before { content: 'Prolog'; }
  pre.src-simula:before { content: 'Simula'; }
  pre.src-tcl:before { content: 'tcl'; }
  pre.src-tex:before { content: 'TeX'; }
  pre.src-plain-tex:before { content: 'Plain TeX'; }
  pre.src-verilog:before { content: 'Verilog'; }
  pre.src-vhdl:before { content: 'VHDL'; }
  pre.src-xml:before { content: 'XML'; }
  pre.src-nxml:before { content: 'XML'; }
  /* add a generic configuration mode; LaTeX export needs an additional
     (add-to-list 'org-latex-listings-langs '(conf " ")) in .emacs */
  pre.src-conf:before { content: 'Configuration File'; }

  table { border-collapse:collapse; }
  caption.t-above { caption-side: top; }
  caption.t-bottom { caption-side: bottom; }
  td, th { vertical-align:top;  }
  th.org-right  { text-align: center;  }
  th.org-left   { text-align: center;   }
  th.org-center { text-align: center; }
  td.org-right  { text-align: right;  }
  td.org-left   { text-align: left;   }
  td.org-center { text-align: center; }
  dt { font-weight: bold; }
  .footpara { display: inline; }
  .footdef  { margin-bottom: 1em; }
  .figure { padding: 1em; }
  .figure p { text-align: center; }
  .equation-container {
    display: table;
    text-align: center;
    width: 100%;
  }
  .equation {
    vertical-align: middle;
  }
  .equation-label {
    display: table-cell;
    text-align: right;
    vertical-align: middle;
  }
  .inlinetask {
    padding: 10px;
    border: 2px solid gray;
    margin: 10px;
    background: #ffffcc;
  }
  #org-div-home-and-up
   { text-align: right; font-size: 70%; white-space: nowrap; }
  textarea { overflow-x: auto; }
  .linenr { font-size: smaller }
  .code-highlighted { background-color: #ffff00; }
  .org-info-js_info-navigation { border-style: none; }
  #org-info-js_console-label
    { font-size: 10px; font-weight: bold; white-space: nowrap; }
  .org-info-js_search-highlight
    { background-color: #ffff00; color: #000000; font-weight: bold; }
  .org-svg { width: 90%; }
  /*]]>*/-->
</style>
<style> body {background-color: #fafad2} img {width: 100%; height: auto;}  figure {text-align: center;} </style>
<script type="text/javascript">
// @license magnet:?xt=urn:btih:e95b018ef3580986a04669f1b5879592219e2a7a&dn=public-domain.txt Public Domain
<!--/*--><![CDATA[/*><!--*/
     function CodeHighlightOn(elem, id)
     {
       var target = document.getElementById(id);
       if(null != target) {
         elem.classList.add("code-highlighted");
         target.classList.add("code-highlighted");
       }
     }
     function CodeHighlightOff(elem, id)
     {
       var target = document.getElementById(id);
       if(null != target) {
         elem.classList.remove("code-highlighted");
         target.classList.remove("code-highlighted");
       }
     }
    /*]]>*///-->
// @license-end
</script>
<script type="text/x-mathjax-config">
    MathJax.Hub.Config({
        displayAlign: "center",
        displayIndent: "0em",

        "HTML-CSS": { scale: 100,
                        linebreaks: { automatic: "false" },
                        webFont: "TeX"
                       },
        SVG: {scale: 100,
              linebreaks: { automatic: "false" },
              font: "TeX"},
        NativeMML: {scale: 100},
        TeX: { equationNumbers: {autoNumber: "AMS"},
               MultLineWidth: "85%",
               TagSide: "right",
               TagIndent: ".8em"
             }
});
</script>
<script type="text/javascript"
        src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.0/MathJax.js?config=TeX-AMS_HTML"></script>
</head>
<body>
<div id="content">
<header>
<h1 class="title">Modern Applied Linear Algebra</h1>
</header><nav id="table-of-contents">
<h2>Table of Contents</h2>
<div id="text-table-of-contents">
<ul>
<li><a href="#Intro">Intro</a>
<ul>
<li><a href="#Materials">Materials</a>
<ul>
<li><a href="#Optional">Optional</a></li>
</ul>
</li>
<li><a href="#Software">Software</a></li>
</ul>
</li>
<li><a href="#Vectors">Vectors</a>
<ul>
<li><a href="#Vector%20visualization">Vector visualization</a>
<ul>
<li><a href="#Linear%20Algebraic%20Geometry%201">Linear Algebraic Geometry 1</a></li>
</ul>
</li>
<li><a href="#Tao%20vector%20spaces">Tao vector spaces</a></li>
<li><a href="#Linear%20combinations%20visualization">Linear combinations visualization</a>
<ul>
<li><a href="#Linear%20Algebraic%20Geometry%202">Linear Algebraic Geometry 2</a></li>
</ul>
</li>
<li><a href="#Tao%20linear%20combinations">Tao linear combinations</a></li>
</ul>
</li>
</ul>
</div>
</nav>

<div id="outline-container-Intro" class="outline-2">
<h2 id="Intro">Intro</h2>
<div class="outline-text-2" id="text-Intro">
<p>
Here we learn:
</p>

<ul class="org-ul">
<li>How to factor gigantic matrices into simpler pieces</li>
<li>How to break up gigantic vectors to simpler subspaces and basis</li>
<li>The Singular Value Decomposition/Principal Component Analysis</li>
<li><a href="https://youtu.be/oGZK3yGF-6k">Matrix calculus</a></li>
<li>Precise constructions of all these concepts and some of their proofs</li>
</ul>

<p>
Once you learn vector spaces and linear transformations, a lot of programming problems become simple linear algebra solutions. 
</p>
</div>

<div id="outline-container-Materials" class="outline-3">
<h3 id="Materials">Materials</h3>
<div class="outline-text-3" id="text-Materials">
<p>
The most efficient path to accomplish this I could find is:
</p>
<ul class="org-ul">
<li>MIT's <a href="https://github.com/mitmath/1806/blob/master/summaries.md">modernized 18.06</a></li>
<li>3Blue1Brown <a href="https://www.youtube.com/playlist?list=PLZHQObOWTQDPD3MizzM2xVFitgF8hE_ab">visualizations</a> when needed</li>
<li>Terence Tao's <a href="https://terrytao.files.wordpress.com/2016/12/linear-algebra-notes.pdf">lecture notes</a> and problem sets to fill in some gaps</li>
</ul>

<p>
I'm also doing a totally optional <a href="https://www.youtube.com/playlist?list=PLIljB45xT85BhzJ-oWNug1YtUjfWp1qAp">playlist</a> <i>Linear Algebraic Geometry</i> you don't have to do but I will do. You'll see later that really all these abstract vector concepts are just parallel lines existing in some abstract subspace and thinking in this way will be beneficial to go on to more advanced linear algebra. He sets everything up as 'this is the special case, how can we make it the general case' in almost every lecture. Then you get linear algebra from 3 different observations: applied everyday linear algebra using software, Terence Tao complete construction of all objects and the <a href="https://www.theguardian.com/science/2021/aug/05/australian-mathematician-discovers-applied-geometry-engraved-on-3700-year-old-tablet">Wildberger</a> more abstract linear algebra that compliments the other two perspectives. 
</p>

<p>
If you are using a laptop/desktop or have Termux installed on your phone you can clone the repo for a local backup to do offline:
</p>

<pre class="example" id="orgf55bdd6">
git clone https://github.com/mitmath/1806.git
</pre>
</div>


<div id="outline-container-Optional" class="outline-4">
<h4 id="Optional">Optional</h4>
<div class="outline-text-4" id="text-Optional">
<p>
I'll mix some of these in but you don't have to do them
</p>

<ul class="org-ul">
<li>Trefethen &amp; Bau's <i>Numerical Linear Algebra</i> <a href="https://people.maths.ox.ac.uk/trefethen/text.html">book</a> (the SVD lectures)</li>
<li>The transformations, autodiff, SVD/PCA <a href="https://computationalthinking.mit.edu/Spring21/">lectures</a> from MIT's <i>Intro to Computational Thinking</i></li>
<li>Titu Andreescu's <i>Essential Linear Algebra with Applications</i> <a href="https://www.maa.org/press/maa-reviews/essential-linear-algebra-with-applications">book</a> which focuses on linear maps between vector spaces as prep to go on to more advanced linear algebra. It's set up like an olympiad problem practice book.</li>
<li>Brown University's CS053 <a href="http://cs.brown.edu/courses/cs053/current/lectures.htm">course</a> <i>Coding the Matrix</i> has open to the public lectures, most of the assignments are done in Python.</li>
</ul>
</div>
</div>
</div>


<div id="outline-container-Software" class="outline-3">
<h3 id="Software">Software</h3>
<div class="outline-text-3" id="text-Software">
<p>
If you want you can just view static notebooks on github, here is an <a href="https://github.com/mitmath/1806/blob/master/lectures/Matrix-Exponentials.ipynb">example</a>. Julia notebooks are only used as a calculator and demonstrations really, most of the homework asks you conceptual questions to think about you don't have to program anything.
</p>

<p>
To make them interactive, use either <a href="https://nextjournal.com/">Nextjournal</a> or <a href="https://mybinder.org/">binder</a> (experimental) and paste in the .ipynb file path from the mitmath/1806 github repo, or install <a href="https://computationalthinking.mit.edu/Spring21/installation/">locally</a>. Local would be the best option to avoid all the problems of slow free container services trying to install requirements. 
</p>

<p>
Almost <a href="https://ocaml.xyz/book/linear-algebra.html">any language</a> will have linear algebra libraries, feel free to translate all the notebook code to your language of choice. If you're on a phone use Google Colab, import SymPy, PyPlot and NumPy and do it all in Python in your browser, much of the Julia notebook code is actually imported PyPlot and other Python libraries anyway.  
</p>
</div>
</div>
</div>

<div id="outline-container-Vectors" class="outline-2">
<h2 id="Vectors">Vectors</h2>
<div class="outline-text-2" id="text-Vectors">
<p>
The MIT class immediately jumps into matrices since it's MIT and can assume that highschool background, we have to learn it from scratch instead.
</p>
</div>

<div id="outline-container-Vector%20visualization" class="outline-3">
<h3 id="Vector%20visualization">Vector visualization</h3>
<div class="outline-text-3" id="text-Vector%20visualization">
<p>
Watch what a <a href="https://youtu.be/fNk_zzaMoSs">vector</a> is (10m length) covering addition and scalars.
</p>
</div>

<div id="outline-container-Linear%20Algebraic%20Geometry%201" class="outline-4">
<h4 id="Linear%20Algebraic%20Geometry%201">Linear Algebraic Geometry 1</h4>
<div class="outline-text-4" id="text-Linear%20Algebraic%20Geometry%201">
<p>
This playlist is <b>optional</b> but highly recommended. This video you learn linear combinations and change of basis vectors to suit different perspectives. These will be the best linear algebra lectures you'll ever watch, if you have the time. 
</p>

<ul class="org-ul">
<li><a href="https://youtu.be/yAb12PWrhV0">Introduction</a> - Wild Linear Algebra A 1 (43m)</li>
</ul>

<p>
He constructs the affine plane from scratch. The vector (8/3, 10,3) you need to full screen to better see exactly where they are. From B, you move right 2 lines, and 2/3 so \(2 + \frac{2}{3}\) which is 8/3. From there you move up 1/3, and 3 so \(3 + \frac{1}{3}\) which is 10/3. Reasons for using the affine plane is this is what a vector space actually looks like, you don't have to impose anything on it artificially like the origin (0,0) in the Cartesian plane or any kind of x, y or z axis. The change of basis explanation here is superior to anything I've seen before. If you forgot highschool, end of this lecture @~30m will teach you how to solve two linear equations with 2 different variables by subtracting and substitution.
</p>

<p>
@34:01 he shows the general 1-dimensional case, then the general 2-dimensional case where you end up getting the determinant, something we will learn soon. Essentially this is the determinant from scratch and you may want to come back to this lecture later when we learn it to see how it's constructed. The exercises if you don't know what a determinant of 0 means in 3D space, there is <a href="https://math.stackexchange.com/questions/355644/what-does-it-mean-to-have-a-determinant-equal-to-zero">solutions</a>, and of course we will learn all this shortly. 
</p>

<p>
In this related <a href="https://youtu.be/Nu-YPJSNFpE">lecture</a> he shows how ancient people made a ruler using just parallel line geometry, which leads to what he claims is modeling the rational continuum.   
</p>
</div>
</div>
</div>

<div id="outline-container-Tao%20vector%20spaces" class="outline-3">
<h3 id="Tao%20vector%20spaces">Tao vector spaces</h3>
<div class="outline-text-3" id="text-Tao%20vector%20spaces">
<p>
Terence Tao's <a href="https://terrytao.files.wordpress.com/2016/12/linear-algebra-notes.pdf">notes</a> reading page 1-19, there's a great intro precisely explaining what linear means, why it's useful to approximate non-linear things with linear transformations, the idea that a scalar can be a vector not a single number, that things like trace and eigenvectors are statistics associated with a matrix, then on page 6 vector definitions begin.
</p>

<p>
If you've never seen set theory watch <a href="https://youtu.be/59WX2V7Vjgg">this</a> or read Tao's short crash course <a href="https://www.math.ucla.edu/~tao/resource/general/115a.3.02f/sets.pdf">here</a>, there's no need to do any proofs. 
</p>

<p>
Page 9 has an interesting comment that mathematicians will only say what vectors do, not what they are, to allow for maximum abstraction of the idea of vectors to numerous different subjects. Note in the axioms, subtraction was never defined instead it is axiom II (associative addition) and axiom IV (additive inverse) being interpreted from v + (-w) to v - w shorthand. This is also v + (-1w). 
</p>

<p>
Page 10 the vector space R<sup>N</sup> is defined as the space of all n-tuples containing scalars (numbers). A tuple is an ordered data structure. This means you only have to research <a href="https://en.wikipedia.org/wiki/Tuple#Properties">properties of tuples</a> to understand a precise construction of vectors and all the operations you can do on them, which is the same for operations on tuple data structures. The term n-tuple means size, so a 3-tuple is (x, y, z) sometimes called a triple.
</p>

<p>
Page 12 Polynomials as vectors, why are his 4 examples not in P<sub>3</sub>(R)? The first exceeds the bounds of degree 3, a rational exponent ie: square root is not a polynomial, e<sup>x</sup> is an exponential function not a polynomial, and the last example polynomials cannot have negative exponents, because x<sup>-3</sup> is 1/x<sup>3</sup> and no polynomial can contain division by a variable.
</p>

<p>
Rest of these notes up to page 19, he goes through all the possible vector spaces you can imagine because they all conform to the same properties of n-tuples, adding them elementwise, scalar multiplication, and being closed under these operations which he describes as meaning you stay within the bounds of that vector space so if it's R<sup>2</sup>, you don't end up with some R<sup>3</sup> result after addition or multiplication. There's errata on page 16 he forgot to include the scalar 10 but you probably figured it out anyway. The point of this was to show there are infinitely many vector spaces, and any kind of picture you see of linear algebra spaces is a metaphor because these spaces often cannot have a picture we can comprehend in multiple dimensions. Case in point the machine learning <a href="./ai.html">workshop</a> we are dealing with gigantic vectors of ridiculous dimensions (rows) of data.
</p>

<p>
Did you get the proof on page 19 that W is a subspace of V because it will be closed anyway? If W doesn't contain zero, it won't matter because 0w = 0, so if you multiply anything in W by a 0 scalar then since 0w=0 just leaving it as (0 \(\cdot\) w) means that zero vector defacto exists anyway. The negative case is the same.
</p>

<p>
Stop reading at page 19 since the remainder is covered in the next 3Blue1Brown lecture (what a plane is, linear combinations, basis vectors). 
</p>
</div>
</div>

<div id="outline-container-Linear%20combinations%20visualization" class="outline-3">
<h3 id="Linear%20combinations%20visualization">Linear combinations visualization</h3>
<div class="outline-text-3" id="text-Linear%20combinations%20visualization">
<ul class="org-ul">
<li>Watch <a href="https://youtu.be/k7RM-ot2NWY">linear combinations</a> and what span, linear combination, linear independence and basis is (10m).</li>

<li>Watch <a href="https://youtu.be/TgKwz5Ikpc8">abstract vector spaces</a> (15m) starting at 1:50. This is the very last 3blue1brown lecture but we're already at that point in Tao's book reasoning about abstract vector subspaces like polynomials. He talks about how <i>the space is really just parallel lines</i> (addition and scaling) and this is another reason why you should watch those Wildberger <a href="https://www.youtube.com/playlist?list=PL01A21B9E302D50C1">videos</a> explaining all these concepts using only the affine parallel plane. @8:47 in this 3blue1brown video, he is demonstrating exactly what Wildberger uses for polynomial encoding which he calls <a href="https://youtu.be/-Ad6pYjCAmg">polynumbers</a>. The end of this video covers the vector subspace axioms we already read.</li>
</ul>
</div>

<div id="outline-container-Linear%20Algebraic%20Geometry%202" class="outline-4">
<h4 id="Linear%20Algebraic%20Geometry%202">Linear Algebraic Geometry 2</h4>
<div class="outline-text-4" id="text-Linear%20Algebraic%20Geometry%202">
<p>
Reminder these lectures are optional.
</p>

<ul class="org-ul">
<li><a href="https://youtu.be/132amJvoLpU">Geometry w/Vectors</a> - Wild Linear Algebra A 2 (44m)</li>
</ul>

<p>
All the laws of vector arithmetic: negative vectors (any vector that goes from the head of one to another vector's head), associative/commutative vectors, distributive law, 0 vector. Linear dependence/independence is also demonstrated. He actually shows tying the geometry to the algebra demonstrating some geometry theorems.
</p>

<p>
@32:48 if lambda = mu:
</p>
<ul class="org-ul">
<li>lambda = 1 - mu</li>
<li>mu(lambda) = 1</li>
<li>2lambda = 1 (since mu = lambda)</li>
<li>lambda = mu = 1/2</li>
</ul>
</div>
</div>
</div>


<div id="outline-container-Tao%20linear%20combinations" class="outline-3">
<h3 id="Tao%20linear%20combinations">Tao linear combinations</h3>
<div class="outline-text-3" id="text-Tao%20linear%20combinations">
<p>
Reading Tao's notes starting at end of page 19 where we left off, the 'flat plane' he talks about is what you saw in the 3blue1brown visualization of a plane slicing the 3D space and going through the origin (0,0,0). His examples of R<sup>3</sup> subspaces, why is the vector (x,y,z) in the line subspace x + 2y + 3z = 0 a vector subspace? Try vector addition and scalar multiplication. 0(x,y,z) = 0x + 02y + 03z = 0. Use a symbolic calculator to <a href="https://www.symbolab.com/solver/linear-equation-calculator/x%20%2B%202y%20%2B%203z%20%3D%200">solve</a> for whatever variable you want, ie: x = -2y -3z. Using vector addition: (x,y,z) + (a,b,c) = x + a + 2y + 2b + 3z + 3c = 0. This is x + a = -2y -2b -3z -3c or substituting x + a back into our original vector addition: (-2y -2b -3z -3c) + 2y + 2b + 3z + 3c = 0 and closed under addition.
</p>

<p>
Page 22, the intersection of two subspaces producing another subspace, at this stage all we can do is reason about a scalar being applied to both the n x n diagonal matrix, and the n x n tr(A) = 0 matrix and you still end up with both a diagonal matrix, and the tr(A) = 0 matrix since scaling the diagonal, if it sums to zero won't change it from summing to zero. We can also reason about the intersection operator (AND) if a vector is in the intersection of two subspaces, then it had to have been in both subspaces to begin with, meaning it was closed in both before and now their combined subspace will also be closed. Union (OR) if a vector is in the union of two subspaces, we can't assume it was in both as the definition of union is combine everything, so there's no logical guarantee that a vector closed in one subspace is now closed in the union with another subspace. I'm sure there will be a proof assignment for this later.
</p>


<p>
TODO
</p>
<hr>
<p>
<a href="./index.html">Home</a>
</p>
</div>
</div>
</div>
</div>
</body>
</html>
